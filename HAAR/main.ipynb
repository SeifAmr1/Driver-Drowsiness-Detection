{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "import numpy as np\n", "import tensorflow as tf\n", "from pygame import mixer\n", "from collections import deque\n", "import time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["frame_counter = 0\n", "prev_time = time.time()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Alarm setup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mixer.init()\n", "try:\n", "    sound = mixer.Sound('alarm.wav')\n", "except:\n", "    print(\"Alarm file not found. Please ensure 'alarm.wav' is in the same directory.\")\n", "    sound = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Classifiers for face and eyes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n", "leye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_lefteye_2splits.xml')\n", "reye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_righteye_2splits.xml')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load trained CNN model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = tf.keras.models.load_model('bestModel.keras')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Preprocess for CNN"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_eye(img):\n", "    img = cv2.resize(img, (64, 64)) / 255.0\n", "    # No more converting grayscale to 3 channels\n", "    img = np.expand_dims(img, axis=-1)  # Add channel dimension for grayscale\n", "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n", "    return img"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cap = cv2.VideoCapture(0)\n", "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n", "score = 0  # Start at zero - only used for alarm, not status\n", "thicc = 2\n", "CONSEC_FRAMES = 5 # Adjust this - still relevant for ALARM\n", "METHOD_USED = \"None\" # Consistent variable naming\n", "eye_status_history = deque(maxlen=3) # initialize history"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["while True:\n", "    ret, frame = cap.read()\n", "    if not ret:\n", "        print(\"Camera error\")\n", "        break\n\n", "        # FPS LOGIC\n", "    frame_counter += 1\n", "    if frame_counter == 10:\n", "        curr_time = time.time()\n", "        elapsed_time = curr_time - prev_time\n", "        fps = frame_counter / elapsed_time\n", "        print(f\"FPS: {fps:.2f}\")\n", "        frame_counter = 0\n", "        prev_time = curr_time\n", "    height, width = frame.shape[:2]\n", "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n", "    # Face detection using Haar Cascade\n", "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n", "    left_eye_detected = right_eye_detected = False\n", "    lpred = rpred = 1 #Initialize to open\n", "    if len(faces) > 0:\n", "        for (fx, fy, fw, fh) in faces:\n", "            # Draw rectangle around the face\n", "            cv2.rectangle(frame, (fx, fy), (fx + fw, fy + fh), (255, 0, 0), 2)\n", "            face_roi = gray[fy:fy+fh, fx:fx+fw]\n\n", "            # Define Eye Regions\n", "            eye_region_height = int(fh * 0.3)  # 30% of face height\n", "            eye_region_width = int(fw * 0.4)   # 40% of face width\n", "            left_eye_x = int(fw * 0.1)        # Left side, 10% from the edge\n", "            left_eye_y = int(fh * 0.2)        # Top, 20% from the top\n", "            right_eye_x = int(fw * 0.5)       # Right side, start at 50%\n", "            right_eye_y = int(fh * 0.2)        # Top, 20% from the top\n\n", "            # Extract Eye ROIs.  Handle edge cases where ROI might be out of bounds\n", "            try:\n", "                left_eye_roi = face_roi[left_eye_y:left_eye_y + eye_region_height, left_eye_x:left_eye_x + eye_region_width]\n", "                right_eye_roi = face_roi[right_eye_y:right_eye_y + eye_region_height, right_eye_x:right_eye_x + eye_region_width]\n", "            except IndexError:\n", "                print(\"Eye ROI out of bounds. Skipping this face.\")\n", "                continue # Skip to the next face\n\n", "            # Detect eyes within the defined regions\n", "            left_eyes = leye_cascade.detectMultiScale(left_eye_roi, scaleFactor=1.1, minNeighbors=5)\n", "            right_eyes = reye_cascade.detectMultiScale(right_eye_roi, scaleFactor=1.1, minNeighbors=5)\n", "            try:\n", "                lprob = 0.0 # initialize\n", "                rprob = 0.0 # initialize\n", "                if len(left_eyes) > 0:\n", "                    (lx, ly, lw, lh) = left_eyes[0]\n", "                    # Adjust coordinates to be relative to the *face_roi*, not the *left_eye_roi*\n", "                    lx_adj = left_eye_x + lx\n", "                    ly_adj = left_eye_y + ly\n", "                    # FORCE TO GRAYSCALE\n", "                    l_eye = face_roi[ly_adj:ly_adj+lh, lx_adj:lx_adj+lw]\n", "                    l_input = preprocess_eye(l_eye)\n", "                    lprob = model.predict(l_input, verbose=0)[0][0]  # Get the probability\n", "                    lpred = 1 if lprob > 0.5 else 0\n", "                    left_eye_detected = True\n", "                    cv2.rectangle(frame, (fx + lx_adj, fy + ly_adj), (fx + lx_adj + lw, fy + ly_adj + lh), (0, 255, 0), 2)\n", "                if len(right_eyes) > 0:\n", "                    (rx, ry, rw, rh) = right_eyes[0]\n", "                    # Adjust coordinates to be relative to the *face_roi*, not the *right_eye_roi*\n", "                    rx_adj = right_eye_x + rx\n", "                    ry_adj = right_eye_y + ry\n", "                    # FORCE TO GRAYSCALE\n", "                    r_eye =  face_roi[ry_adj:ry_adj+rh, rx_adj:rx_adj+rw]\n", "                    r_input = preprocess_eye(r_eye)\n", "                    rprob = model.predict(r_input, verbose=0)[0][0]  # Get the probability\n", "                    rpred = 1 if rprob > 0.5 else 0\n", "                    right_eye_detected = True\n", "                    cv2.rectangle(frame, (fx + rx_adj, fy + ry_adj), (fx + rx_adj + rw, fy + ry_adj + rh), (0, 0, 255), 2)\n", "            except Exception as e:\n", "                print(f\"Error during eye processing: {e}\")\n", "                pass\n", "            if left_eye_detected or right_eye_detected:\n", "                METHOD_USED = \"Haar + CNN\"\n\n", "    # Determine STATUS based ONLY on current frame's model predictions\n", "    CNN_closed = (lpred == 0 and rpred == 0)  # Both eyes predicted closed\n\n", "    # ADD HISTORY TO SMOOTH PREDICTIONS\n", "    if CNN_closed:\n", "        eye_status_history.append(1)\n", "    else:\n", "        eye_status_history.append(0)\n\n", "    # Decide status and calculate the score\n", "    if sum(eye_status_history) >= 2: # This line is same to the provided code\n", "        score += 1\n", "        status = \"Closed\" # Status determined by HISTORY\n", "    else:\n", "        score -= 1\n", "        status = \"Open\"  # Status determined by HISTORY\n", "    score = max(0, score) # cap the score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    int_score = int(score)\n\n", "    # Print the status and score to the console\n", "    print(f\"Frame Status: {status}, Score: {int_score}\")\n\n", "    # Display information on the frame\n", "    cv2.putText(frame, f\"Status: {status}\", (10, height - 50), font, 1, (255, 255, 255), 1)\n", "    cv2.putText(frame, f\"Score: {int_score}\", (10, height - 30), font, 1, (255, 255, 255), 1)  # Display as int\n", "    cv2.putText(frame, f\"Method: {METHOD_USED}\", (10, height - 10), font, 1, (0, 255, 255), 1)\n\n", "    # Alarm logic - BASED on SCORE, NOT STATUS\n", "    if score > CONSEC_FRAMES:\n", "        if sound and not mixer.get_busy():\n", "            sound.play()\n", "        cv2.rectangle(frame, (0, 0), (width, height), (0, 0, 255), thicc)\n", "        thicc = thicc + 2 if thicc < 16 else thicc - 2\n", "        thicc = max(2, thicc)\n", "    else:\n", "        if sound:\n", "            sound.stop()\n", "    cv2.imshow('Drowsiness Detection', frame)\n", "    if cv2.waitKey(1) & 0xFF == ord('q'):\n", "        break"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cap.release()\n", "cv2.destroyAllWindows()\n", "if sound:\n", "    mixer.quit()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}