{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from mtcnn import MTCNN\n", "import cv2\n", "import numpy as np\n", "import tensorflow as tf\n", "from pygame import mixer\n", "from collections import deque\n", "import time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["frame_counter = 0\n", "prev_time = time.time()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load MTCNN detector"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["detector = MTCNN()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load pre-trained eye closure classification model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = tf.keras.models.load_model('finalModel_Augmented.keras')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Alarm setup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mixer.init()\n", "try:\n", "    alarm = mixer.Sound('alarm.wav')\n", "except:\n", "    print(\"Warning: alarm.wav not found.\")\n", "    alarm = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["score = 0\n", "SCORE_THRESHOLD = 5\n", "eye_status_history = deque(maxlen=3)\n", "font = cv2.FONT_HERSHEY_SIMPLEX"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_eye(img):\n", "    img = cv2.resize(img, (64, 64))\n", "    img = img / 255.0\n", "    img = np.expand_dims(img, axis=0)\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cap = cv2.VideoCapture(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["while True:\n", "    ret, frame = cap.read()\n", "    if not ret:\n", "        break\n\n", "    #FPS LOGIC\n", "    frame_counter += 1\n", "    if frame_counter == 10:\n", "        curr_time = time.time()\n", "        elapsed_time = curr_time - prev_time\n", "        fps = frame_counter / elapsed_time\n", "        print(f\"FPS: {fps:.2f}\")\n", "        frame_counter = 0\n", "        prev_time = curr_time\n", "    faces = detector.detect_faces(frame)\n", "    for face in faces:\n", "        bbox = face['box']\n", "        keypoints = face['keypoints']\n", "        left_eye_x, left_eye_y = keypoints['left_eye']\n", "        right_eye_x, right_eye_y = keypoints['right_eye']\n", "        eye_width = abs(left_eye_x - right_eye_x)\n\n", "        # Get ROIs for left and right eye\n", "        lx1 = max(0, int(left_eye_x - eye_width / 2))\n", "        ly1 = max(0, int(left_eye_y - eye_width / 2))\n", "        lx2 = min(frame.shape[1], int(left_eye_x + eye_width / 2))\n", "        ly2 = min(frame.shape[0], int(left_eye_y + eye_width / 2))\n", "        rx1 = max(0, int(right_eye_x - eye_width / 2))\n", "        ry1 = max(0, int(right_eye_y - eye_width / 2))\n", "        rx2 = min(frame.shape[1], int(right_eye_x + eye_width / 2))\n", "        ry2 = min(frame.shape[0], int(right_eye_y + eye_width / 2))\n", "        try:\n", "            left_eye_region = frame[ly1:ly2, lx1:lx2]\n", "            right_eye_region = frame[ry1:ry2, rx1:rx2]\n\n", "            # left_eye_gray = cv2.cvtColor(left_eye_region, cv2.COLOR_BGR2GRAY)\n", "            # right_eye_gray = cv2.cvtColor(right_eye_region, cv2.COLOR_BGR2GRAY)\n\n", "            # Preprocess\n", "            left_input = preprocess_eye(left_eye_region)\n", "            right_input = preprocess_eye(right_eye_region)\n", "            lpred = model.predict(left_input, verbose=0)[0][0]\n", "            rpred = model.predict(right_input, verbose=0)[0][0]\n", "            l_state = 1 if lpred > 0.5 else 0\n", "            r_state = 1 if rpred > 0.5 else 0\n", "            eyes_closed = (l_state == 0 and r_state == 0)\n", "            eye_status_history.append(1 if eyes_closed else 0)\n", "            if sum(eye_status_history) >= 2:\n", "                score += 1\n", "            else:\n", "                score -= 1\n", "            score = max(0, score)\n\n", "            # Alarm logic\n", "            if score > SCORE_THRESHOLD:\n", "                if alarm and not mixer.get_busy():\n", "                    alarm.play()\n", "                cv2.putText(frame, \"DROWSY!\", (10, 60), font, 1, (0, 0, 255), 2)\n", "                cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 4)\n", "            else:\n", "                if alarm:\n", "                    alarm.stop()\n", "            status = \"Closed\" if eyes_closed else \"Open\"\n", "            cv2.putText(frame, f\"Status: {status}\", (bbox[0], bbox[1] - 20), font, 0.7, (0, 255, 0), 2)\n", "            cv2.putText(frame, f\"Score: {score}\", (bbox[0], bbox[1] - 50), font, 0.7, (255, 255, 255), 2)\n", "        except Exception as e:\n", "            print(\"Prediction error:\", e)\n", "            continue\n\n", "        # Draw bounding box and landmarks\n", "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), (0, 255, 0), 2)\n", "        cv2.circle(frame, (left_eye_x, left_eye_y), 5, (255, 0, 0), -1)\n", "        cv2.circle(frame, (right_eye_x, right_eye_y), 5, (0, 0, 255), -1)\n", "    cv2.imshow(\"Frame\", frame)\n", "    cv2.imshow(\"Left Eye\", left_eye_region)\n", "    cv2.imshow(\"Right Eye\", right_eye_region)\n", "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n", "        break"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cap.release()\n", "cv2.destroyAllWindows()\n", "if alarm:\n", "    mixer.quit()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<br>\n", "from mtcnn import MTCNN<br>\n", "import cv2<br>\n", "import numpy as np<br>\n", "import tensorflow as tf<br>\n", "from pygame import mixer<br>\n", "from collections import deque<br>\n", "<br>\n", "# Load MTCNN detector<br>\n", "detector = MTCNN()<br>\n", "<br>\n", "# Load pre-trained eye closure classification model<br>\n", "# model = tf.keras.models.load_model('finalModel_Augmented.keras')<br>\n", "interpreter = tf.lite.Interpreter(model_path=\"finalModel_dyn2.tflite\")<br>\n", "interpreter.allocate_tensors()<br>\n", "<br>\n", "input_details = interpreter.get_input_details()<br>\n", "output_details = interpreter.get_output_details()<br>\n", "<br>\n", "def predict_eye_state(eye_input):<br>\n", "    interpreter.set_tensor(input_details[0]['index'], eye_input.astype(np.float32))<br>\n", "    interpreter.invoke()<br>\n", "    output_data = interpreter.get_tensor(output_details[0]['index'])  # shape: (1, 2)<br>\n", "    open_prob = output_data[0][0]<br>\n", "    closed_prob = output_data[0][1]<br>\n", "    return open_prob, closed_prob<br>\n", "<br>\n", "<br>\n", "<br>\n", "# Alarm setup<br>\n", "mixer.init()<br>\n", "try:<br>\n", "    alarm = mixer.Sound('alarm.wav')<br>\n", "except:<br>\n", "    print(\"Warning: alarm.wav not found.\")<br>\n", "    alarm = None<br>\n", "<br>\n", "# Parameters<br>\n", "score = 0<br>\n", "SCORE_THRESHOLD = 10<br>\n", "eye_status_history = deque(maxlen=5)<br>\n", "font = cv2.FONT_HERSHEY_SIMPLEX<br>\n", "<br>\n", "def preprocess_eye(img):<br>\n", "    img = cv2.resize(img, (64, 64))<br>\n", "    img = img / 255.0<br>\n", "    img = np.expand_dims(img, axis=0)<br>\n", "    return img<br>\n", "<br>\n", "cap = cv2.VideoCapture(0)<br>\n", "<br>\n", "while True:<br>\n", "    ret, frame = cap.read()<br>\n", "    if not ret:<br>\n", "        break<br>\n", "<br>\n", "    faces = detector.detect_faces(frame)<br>\n", "<br>\n", "    for face in faces:<br>\n", "        bbox = face['box']<br>\n", "        keypoints = face['keypoints']<br>\n", "<br>\n", "        left_eye_x, left_eye_y = keypoints['left_eye']<br>\n", "        right_eye_x, right_eye_y = keypoints['right_eye']<br>\n", "        eye_width = abs(left_eye_x - right_eye_x)<br>\n", "<br>\n", "        # Get ROIs for left and right eye<br>\n", "        lx1 = max(0, int(left_eye_x - eye_width / 2))<br>\n", "        ly1 = max(0, int(left_eye_y - eye_width / 2))<br>\n", "        lx2 = min(frame.shape[1], int(left_eye_x + eye_width / 2))<br>\n", "        ly2 = min(frame.shape[0], int(left_eye_y + eye_width / 2))<br>\n", "<br>\n", "        rx1 = max(0, int(right_eye_x - eye_width / 2))<br>\n", "        ry1 = max(0, int(right_eye_y - eye_width / 2))<br>\n", "        rx2 = min(frame.shape[1], int(right_eye_x + eye_width / 2))<br>\n", "        ry2 = min(frame.shape[0], int(right_eye_y + eye_width / 2))<br>\n", "<br>\n", "        try:<br>\n", "            left_eye_region = frame[ly1:ly2, lx1:lx2]<br>\n", "            right_eye_region = frame[ry1:ry2, rx1:rx2]<br>\n", "<br>\n", "            # left_eye_gray = cv2.cvtColor(left_eye_region, cv2.COLOR_BGR2GRAY)<br>\n", "            # right_eye_gray = cv2.cvtColor(right_eye_region, cv2.COLOR_BGR2GRAY)<br>\n", "<br>\n", "            # Preprocess<br>\n", "            left_input = preprocess_eye(left_eye_region)<br>\n", "            right_input = preprocess_eye(right_eye_region)<br>\n", "<br>\n", "            # lpred = model.predict(left_input, verbose=0)[0][0]<br>\n", "            # rpred = model.predict(right_input, verbose=0)[0][0]<br>\n", "            #<br>\n", "            # l_state = 1 if lpred > 0.5 else 0<br>\n", "            # r_state = 1 if rpred > 0.5 else 0<br>\n", "            l_open, l_closed = predict_eye_state(left_input)<br>\n", "            r_open, r_closed = predict_eye_state(right_input)<br>\n", "<br>\n", "            l_state = 0 if l_closed <= 0.5 else 1  # 1 = open, 0 = closed<br>\n", "            r_state = 0 if r_closed <= 0.5 else 1<br>\n", "<br>\n", "            eyes_closed = (l_state == 0 and r_state == 0)<br>\n", "            eye_status_history.append(1 if eyes_closed else 0)<br>\n", "<br>\n", "            if sum(eye_status_history) >= 4:<br>\n", "                score += 1<br>\n", "            else:<br>\n", "                score -= 1<br>\n", "<br>\n", "            score = max(0, score)<br>\n", "<br>\n", "            # Alarm logic<br>\n", "            if score > SCORE_THRESHOLD:<br>\n", "                if alarm and not mixer.get_busy():<br>\n", "                    alarm.play()<br>\n", "                cv2.putText(frame, \"DROWSY!\", (10, 60), font, 1, (0, 0, 255), 2)<br>\n", "                cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 4)<br>\n", "            else:<br>\n", "                if alarm:<br>\n", "                    alarm.stop()<br>\n", "<br>\n", "            status = \"Closed\" if eyes_closed else \"Open\"<br>\n", "            cv2.putText(frame, f\"Status: {status}\", (bbox[0], bbox[1] - 20), font, 0.7, (0, 255, 0), 2)<br>\n", "            cv2.putText(frame, f\"Score: {score}\", (bbox[0], bbox[1] - 50), font, 0.7, (255, 255, 255), 2)<br>\n", "<br>\n", "        except Exception as e:<br>\n", "            print(\"Prediction error:\", e)<br>\n", "            continue<br>\n", "<br>\n", "        # Draw bounding box and landmarks<br>\n", "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[0] + bbox[2], bbox[1] + bbox[3]), (0, 255, 0), 2)<br>\n", "        cv2.circle(frame, (left_eye_x, left_eye_y), 5, (255, 0, 0), -1)<br>\n", "        cv2.circle(frame, (right_eye_x, right_eye_y), 5, (0, 0, 255), -1)<br>\n", "<br>\n", "        cv2.imshow(\"Frame\", frame)<br>\n", "        cv2.imshow(\"Left Eye\", left_eye_region)<br>\n", "        cv2.imshow(\"Right Eye\", right_eye_region)<br>\n", "<br>\n", "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):<br>\n", "        break<br>\n", "<br>\n", "cap.release()<br>\n", "cv2.destroyAllWindows()<br>\n", "if alarm:<br>\n", "    mixer.quit()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}